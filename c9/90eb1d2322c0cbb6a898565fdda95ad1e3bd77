From: krewat@kilonet.net (Arthur Krewat)
Date: Mon, 6 Nov 2017 19:34:34 -0500
Subject: [TUHS] origins of void* -- Apology!
In-Reply-To: <065d01d3575e$f71f6ad0$e55e4070$@ronnatalie.com>
References: <CANCZdfoLzdp6q4VsXo+cZ_gwMhyRxk2FT-jh2Dz2Ggt5pQdfJg@mail.gmail.com>
 <7617c69abf46fbe3f206c6208000fe3b26854359@webmail.yaccman.com>
 <065d01d3575e$f71f6ad0$e55e4070$@ronnatalie.com>
Message-ID: <fa31cbb0-c3a3-7c4a-1ec3-a59d06ecb5d9@kilonet.net>

char (at least these days) is signed. So really, it's 7-bit ASCII.

I've been bitten by the 7-bit ASCII thing when it comes to modern 
character sets. unsigned char gets tiresome ;)


On 11/6/2017 7:25 PM, Ron Natalie wrote:
>
> I believe one of C’s biggest failings is that they did not solve the 
> schizophrenic definition of char*.
>
> Char* as historically implemented and then  CODIFIED in the C and C++ 
> standards is both the basic character type as well as the smallest 
> addressable unit of storage.
>
> Thiswas all peachy keen in the 8 bit ASCII days (and even earlier 
> alternative character sets such as EBCDIC, and its predecessors and 
> other historical character sets like UNIVAC’s fielddata_), but fell 
> apart when we started into the 16 bit and larger UNICODE._
>
> __
>
> _We needed a basic memory type that had sizeof == 1 (which void*) did 
> not meet and release char from having to play double duty._
>
> __
>
> __
>
> __
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://minnie.tuhs.org/pipermail/tuhs/attachments/20171106/fb57d3be/attachment.html>

